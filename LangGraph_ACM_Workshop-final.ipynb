{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jer4R8_5Hh63"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install langgraph groq python-dotenv PyPDF2 langchain-groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N54DU0h3IAzJ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73hKELFFICKb"
      },
      "outputs": [],
      "source": [
        "resume_path = \"/content/drive/MyDrive/DG'S Resume.pdf\"\n",
        "jd_path = \"/content/drive/MyDrive/jd1.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5XQs_NtnVx1"
      },
      "source": [
        "## Extracting Resume and JD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUNNbXU4IIGE"
      },
      "outputs": [],
      "source": [
        "from PyPDF2 import PdfReader\n",
        "\n",
        "def extract_text_from_pdf_pypdf2(pdf_path):\n",
        "    try:\n",
        "        reader = PdfReader(pdf_path)\n",
        "        text = \"\"\n",
        "        for page in reader.pages:\n",
        "            extracted_page_text = page.extract_text()\n",
        "            if extracted_page_text:\n",
        "                text += extracted_page_text + \"\\n\"\n",
        "        return text\n",
        "    except FileNotFoundError:\n",
        "        return f\"Error: The file at path '{pdf_path}' was not found.\"\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\"\n",
        "\n",
        "resume = extract_text_from_pdf_pypdf2(resume_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mc0CPHFGIMWx"
      },
      "outputs": [],
      "source": [
        "def extract_text_from_txt(txt_path):\n",
        "    try:\n",
        "        with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            text = f.read()\n",
        "        return text\n",
        "    except FileNotFoundError:\n",
        "        return f\"Error: The file at path '{txt_path}' was not found.\"\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\"\n",
        "\n",
        "jd = extract_text_from_txt(jd_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7K6OBaZuIPT1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "GROQ_API_KEY=\"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\"\n",
        "os.environ['GROQ_API_KEY'] = GROQ_API_KEY\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLt7qtxgIoPG"
      },
      "source": [
        "## First Iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMudrBy4Iq38"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from groq import Groq\n",
        "\n",
        "# Load API Key\n",
        "load_dotenv()\n",
        "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
        "\n",
        "# Set up Groq LLM (using Mixtral)\n",
        "from langchain_groq import ChatGroq\n",
        "llm = ChatGroq(api_key=groq_api_key, model_name=\"meta-llama/llama-4-scout-17b-16e-instruct\")\n",
        "\n",
        "# Step 1: Define the state schema\n",
        "from typing import TypedDict, Optional,Literal\n",
        "\n",
        "class ResumeState(TypedDict):\n",
        "    resume: str\n",
        "    job_description: str\n",
        "    analysis: Optional[str]\n",
        "    gaps: Optional[str]\n",
        "    enhanced_resume: Optional[str]\n",
        "\n",
        "# Step 2: Define functions (LangChain Runnables)\n",
        "\n",
        "def analyze_resume(state: ResumeState) -> ResumeState:\n",
        "    prompt = f\"\"\"Analyze the following resume and list its key strengths and weaknesses:\\n\\n{state['resume']}\"\"\"\n",
        "    result = llm.invoke(prompt)\n",
        "    return {**state, \"analysis\": result.content}\n",
        "\n",
        "def compare_resume_with_jd(state: ResumeState) -> ResumeState:\n",
        "    prompt = f\"\"\"Given the resume:\\n{state['resume']}\\n\\nAnd this job description:\\n{state['job_description']}\\n\\nList the gaps, missing skills, and mismatch areas.\"\"\"\n",
        "    result = llm.invoke(prompt)\n",
        "    return {**state, \"gaps\": result.content}\n",
        "\n",
        "def enhance_resume(state: ResumeState) -> ResumeState:\n",
        "    prompt = f\"\"\"Enhance the following resume:\\n{state['resume']}\\n\\nBased on this job description:\\n{state['job_description']}\\n\\nConsider these findings:\\nAnalysis: {state['analysis']}\\nGaps: {state['gaps']}\"\"\"\n",
        "    result = llm.invoke(prompt)\n",
        "    return {**state, \"enhanced_resume\": result.content}\n",
        "\n",
        "# Step 3: Build LangGraph (Linear)\n",
        "builder = StateGraph(ResumeState)\n",
        "\n",
        "builder.add_node(\"AnalyzeResume\", RunnableLambda(analyze_resume))\n",
        "builder.add_node(\"CompareWithJD\", RunnableLambda(compare_resume_with_jd))\n",
        "builder.add_node(\"EnhanceResume\", RunnableLambda(enhance_resume))\n",
        "\n",
        "builder.set_entry_point(\"AnalyzeResume\")\n",
        "builder.add_edge(\"AnalyzeResume\", \"CompareWithJD\")\n",
        "builder.add_edge(\"CompareWithJD\", \"EnhanceResume\")\n",
        "builder.add_edge(\"EnhanceResume\", END)\n",
        "\n",
        "graph = builder.compile()\n",
        "\n",
        "initial_state = {\n",
        "    \"resume\": resume,\n",
        "    \"job_description\": jd,\n",
        "    \"analysis\": None,\n",
        "    \"gaps\": None,\n",
        "    \"enhanced_resume\": None,\n",
        "}\n",
        "\n",
        "final_state = graph.invoke(initial_state)\n",
        "\n",
        "# Step 5: Output result\n",
        "print(\"\\nâœ… Resume Analysis:\\n\", final_state[\"analysis\"])\n",
        "print(\"\\nðŸ” Job Match Gaps:\\n\", final_state[\"gaps\"])\n",
        "print(\"\\nðŸš€ Enhanced Resume:\\n\", final_state[\"enhanced_resume\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tn28zUuiIyW9"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Markdown, display\n",
        "display(Markdown(final_state[\"analysis\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJ8DBcqUWO8V"
      },
      "source": [
        "## Second Iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypmC0DskWMTS"
      },
      "outputs": [],
      "source": [
        "class ResumeState(TypedDict):\n",
        "    resume: str\n",
        "    job_description: str\n",
        "    analysis: Optional[str]\n",
        "    gaps: Optional[str]\n",
        "    enhanced_resume: Optional[str]\n",
        "    summary: Optional[str]\n",
        "    path_decision: Optional[Literal[\"rewrite\", \"skip\"]]\n",
        "\n",
        "\n",
        "def evaluate_gaps(state: ResumeState) -> ResumeState:\n",
        "    prompt = f\"\"\"Based on the following gap analysis between resume and job description, decide if the resume needs rewriting.\n",
        "    If the resume is mostly aligned, return 'skip'. If there are many issues or gaps, return 'rewrite'.\\n\\nGaps:\\n{state['gaps']}\"\"\"\n",
        "    decision = llm.invoke(prompt).content.lower()\n",
        "    if \"rewrite\" in decision:\n",
        "        # Return the state with the decision added\n",
        "        return {**state, \"path_decision\": \"rewrite\"}\n",
        "    else:\n",
        "        # Return the state with the decision added\n",
        "        return {**state, \"path_decision\": \"skip\"}\n",
        "\n",
        "\n",
        "def summarize_result(state: ResumeState) -> ResumeState:\n",
        "    summary = f\"\"\"\n",
        "Analysis:\\n{state['analysis']}\n",
        "\n",
        " Gaps:\\n{state['gaps']}\n",
        "\n",
        "Final Resume:\\n{state.get('enhanced_resume', 'Original resume retained.')}\n",
        "\"\"\"\n",
        "    return {**state, \"summary\": summary}\n",
        "\n",
        "\n",
        "builder = StateGraph(ResumeState)\n",
        "\n",
        "# Add nodes\n",
        "builder.add_node(\"AnalyzeResume\", RunnableLambda(analyze_resume))\n",
        "builder.add_node(\"CompareWithJD\", RunnableLambda(compare_resume_with_jd))\n",
        "builder.add_node(\"EvaluateGaps\", RunnableLambda(evaluate_gaps))\n",
        "builder.add_node(\"EnhanceResume\", RunnableLambda(enhance_resume))\n",
        "builder.add_node(\"Summarize\", RunnableLambda(summarize_result))\n",
        "\n",
        "# Entry point\n",
        "builder.set_entry_point(\"AnalyzeResume\")\n",
        "\n",
        "# Linear flow to start\n",
        "builder.add_edge(\"AnalyzeResume\", \"CompareWithJD\")\n",
        "builder.add_edge(\"CompareWithJD\", \"EvaluateGaps\")\n",
        "\n",
        "# Conditional edge from EvaluateGaps\n",
        "builder.add_conditional_edges(\n",
        "    \"EvaluateGaps\",\n",
        "    # Function that returns the path_decision from the state\n",
        "    lambda state: state[\"path_decision\"],\n",
        "    {\n",
        "        \"rewrite\": \"EnhanceResume\",\n",
        "        \"skip\": \"Summarize\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# After enhancement, go to summary\n",
        "builder.add_edge(\"EnhanceResume\", \"Summarize\")\n",
        "\n",
        "# End\n",
        "builder.add_edge(\"Summarize\", END)\n",
        "\n",
        "graph = builder.compile()\n",
        "\n",
        "final_state = graph.invoke(initial_state)\n",
        "\n",
        "print(\"\\nðŸŽ¯ Summary:\\n\")\n",
        "print(final_state[\"summary\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwztKm_wWWnR"
      },
      "outputs": [],
      "source": [
        "display(Markdown(final_state[\"summary\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4tW_EE4W_Ea"
      },
      "source": [
        "## Third Iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoXmsb3eXSU8"
      },
      "outputs": [],
      "source": [
        "SERPER_API_KEY = \"19ed5e2a267bec08c514815b99226d6c788603d7\"\n",
        "\n",
        "os.environ[\"SERPER_API_KEY\"] = SERPER_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_6QOHdGXYEv"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2UGIN4mXCX9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
        "# Load API Keys\n",
        "load_dotenv()\n",
        "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
        "serper_api_key = os.getenv(\"SERPER_API_KEY\")\n",
        "\n",
        "# Set up Groq LLM\n",
        "llm = ChatGroq(api_key=groq_api_key, model_name=\"meta-llama/llama-4-scout-17b-16e-instruct\")\n",
        "\n",
        "# Define state schema\n",
        "from typing import TypedDict, Optional, Literal\n",
        "\n",
        "class ResumeState(TypedDict):\n",
        "    resume: str\n",
        "    job_description: str\n",
        "    analysis: Optional[str]\n",
        "    gaps: Optional[str]\n",
        "    enhanced_resume: Optional[str]\n",
        "    summary: Optional[str]\n",
        "    path_decision: Optional[Literal[\"rewrite\", \"skip\"]]\n",
        "    job_suggestions: Optional[str]\n",
        "\n",
        "# Define functions\n",
        "def analyze_resume(state: ResumeState) -> ResumeState:\n",
        "    prompt = f\"Analyze the following resume and list its key strengths and weaknesses:\\n\\n{state['resume']}\"\n",
        "    result = llm.invoke(prompt)\n",
        "    return {**state, \"analysis\": result.content}\n",
        "\n",
        "def compare_resume_with_jd(state: ResumeState) -> ResumeState:\n",
        "    prompt = f\"Given the resume:\\n{state['resume']}\\n\\nAnd this job description:\\n{state['job_description']}\\n\\nList the gaps, missing skills, and mismatch areas.\"\n",
        "    result = llm.invoke(prompt)\n",
        "    return {**state, \"gaps\": result.content}\n",
        "\n",
        "def evaluate_gaps(state: ResumeState) -> ResumeState:\n",
        "    prompt = f\"Based on the following gap analysis between resume and job description, decide if the resume needs rewriting. If mostly aligned, return 'skip'. If there are many issues, return 'rewrite'.\\n\\nGaps:\\n{state['gaps']}\"\n",
        "    decision = llm.invoke(prompt).content.lower()\n",
        "    return {**state, \"path_decision\": \"rewrite\" if \"rewrite\" in decision else \"skip\"}\n",
        "\n",
        "def enhance_resume(state: ResumeState) -> ResumeState:\n",
        "    prompt = f\"Enhance this resume:\\n{state['resume']}\\n\\nBased on this job description:\\n{state['job_description']}\\n\\nFindings:\\nAnalysis: {state['analysis']}\\nGaps: {state['gaps']}\"\n",
        "    result = llm.invoke(prompt)\n",
        "    return {**state, \"enhanced_resume\": result.content}\n",
        "\n",
        "def summarize_result(state: ResumeState) -> ResumeState:\n",
        "    summary = f\"\"\"\n",
        "âœ… Analysis:\\n{state['analysis']}\n",
        "\n",
        "ðŸ” Gaps:\\n{state['gaps']}\n",
        "\n",
        "ðŸš€ Final Resume:\\n{state.get('enhanced_resume', 'Original resume retained.')}\n",
        "\n",
        "ðŸ§  Job Suggestions:\\n{state.get('job_suggestions', 'No suggestions found.')}\n",
        "\"\"\"\n",
        "    return {**state, \"summary\": summary}\n",
        "\n",
        "# ðŸ” Job Suggestion Agent using SERPER API\n",
        "def fetch_job_suggestions(state: ResumeState) -> ResumeState:\n",
        "    query = f\"{state['job_description'].splitlines()[0]} jobs near me\"\n",
        "    search = GoogleSerperAPIWrapper(serper_api_key=serper_api_key)\n",
        "    results = search.results(query)\n",
        "\n",
        "    suggestions = []\n",
        "    for result in results.get(\"organic\", [])[:5]:\n",
        "        title = result.get(\"title\", \"\")\n",
        "        link = result.get(\"link\", \"\")\n",
        "        suggestions.append(f\"- {title}\\n  ðŸ”— {link}\")\n",
        "\n",
        "    jobs = \"\\n\".join(suggestions) or \"No relevant jobs found.\"\n",
        "    return {**state, \"job_suggestions\": jobs}\n",
        "\n",
        "# Build LangGraph\n",
        "builder = StateGraph(ResumeState)\n",
        "\n",
        "# Add nodes\n",
        "builder.add_node(\"AnalyzeResume\", RunnableLambda(analyze_resume))\n",
        "builder.add_node(\"CompareWithJD\", RunnableLambda(compare_resume_with_jd))\n",
        "builder.add_node(\"EvaluateGaps\", RunnableLambda(evaluate_gaps))\n",
        "builder.add_node(\"EnhanceResume\", RunnableLambda(enhance_resume))\n",
        "builder.add_node(\"FetchJobs\", RunnableLambda(fetch_job_suggestions))\n",
        "builder.add_node(\"Summarize\", RunnableLambda(summarize_result))\n",
        "\n",
        "# Entry\n",
        "builder.set_entry_point(\"AnalyzeResume\")\n",
        "\n",
        "# Flow\n",
        "builder.add_edge(\"AnalyzeResume\", \"CompareWithJD\")\n",
        "builder.add_edge(\"CompareWithJD\", \"EvaluateGaps\")\n",
        "\n",
        "# Conditional enhancement or skip\n",
        "builder.add_conditional_edges(\n",
        "    \"EvaluateGaps\",\n",
        "    lambda state: state[\"path_decision\"],\n",
        "    {\n",
        "        \"rewrite\": \"EnhanceResume\",\n",
        "        \"skip\": \"FetchJobs\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# After enhance, go to job fetch\n",
        "builder.add_edge(\"EnhanceResume\", \"FetchJobs\")\n",
        "\n",
        "# Then to summary\n",
        "builder.add_edge(\"FetchJobs\", \"Summarize\")\n",
        "\n",
        "# End\n",
        "builder.add_edge(\"Summarize\", END)\n",
        "\n",
        "graph = builder.compile()\n",
        "\n",
        "initial_state = {\n",
        "    \"resume\": resume,\n",
        "    \"job_description\": jd,\n",
        "    \"analysis\": None,\n",
        "    \"gaps\": None,\n",
        "    \"enhanced_resume\": None,\n",
        "    \"path_decision\": None,\n",
        "    \"summary\": None,\n",
        "    \"job_suggestions\": None,\n",
        "}\n",
        "\n",
        "final_state = graph.invoke(initial_state)\n",
        "\n",
        "# Output\n",
        "print(\"\\nðŸŽ¯ Final Summary:\\n\")\n",
        "print(final_state[\"summary\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odDYAn0OXD92"
      },
      "outputs": [],
      "source": [
        "display(Markdown(final_state[\"summary\"]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
